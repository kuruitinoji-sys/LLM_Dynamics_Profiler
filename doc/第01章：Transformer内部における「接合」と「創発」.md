# 🌐 情報動力学：LLM構造の物理数理的詳解

## 第1章：Transformer内部における「接合」と「創発」

推論とは、Transformerという幾何学的構造体が、静的なポテンシャル制約（HHH）と動的な流体運動（連続の拘束）を「接合（Coupling）」させ、一つの物理現象として結実させるプロセスである。本章では、この接合部におけるエネルギー変換と、そこから創発する運動方程式を定式化する。
本稿では、基盤モデルは強い事前分布（重力井戸）を形成し、インスタンス化により局所的な自由度が増えることで跳躍が観測され得る、と仮定する。

\textbf{スコープ：}本章は観測・同定の枠組みを提示することを目的とし、推論過程の制御（操作）問題は扱わない。

### 観測量（proxy）と推定手順（準定常化／射影）

本稿では、内部状態そのものの直接観測ではなく、入出力から構成される観測量（proxy）を定義し、準定常化（平滑化）により同定可能な成分を抽出する。

- **観測列**：生成テキストを埋め込み空間へ写像したベクトル列を $x_n$ とする。
- **準定常化（FEP：Floating Equilibrium Point）**：指数移動平均（EMA）により「動的重心」$\bar{x}_n$ を定義する。

$$\bar{x}_{n+1} = \bar{x}_n + \alpha (x_n - \bar{x}_n)$$

必要に応じて $\bar{x}_{n+1} \leftarrow \bar{x}_{n+1}/\|\bar{x}_{n+1}\|$ として正規化する。

- **例：proxy（最小）**：
  - 偏差（テンション）$\Psi_n = \|x_n - \bar{x}_n\|$
  - 運動エネルギー $K_n = \tfrac{1}{2}\|x_n - \bar{x}_n\|^2$

- **推定（射影）の基本形**：条件（モデル・温度等）を固定し、複数試行の観測列から proxy の統計量を構成し、$U(z,t)$ や $M_t$ の寄与を proxy 空間へ射影して推定する（推定の非一意性は限界として扱う）。

### 1.1 Attention機構の物理的再定義：エネルギー分配器としての接合

標準的なTransformerのAttention式 $Softmax(\frac{QK^T}{\sqrt{d_k}})V$ は、情報動力学の視点において、単なる類似度計算ではない。それは、空間の各点におけるエネルギー準位を瞬時に決定し、流体の行き先を制御する**「動的ポテンシャル分配関数」**として再定義される。

#### 1.1.1 接合Attention方程式 (Coupled Attention Equation)

推論時、Attentionスコア $A(z, t)$ は、表層的な意味的類似度（$QK^T$）に対し、深層の「韻律層」から湧き上がる接合ポテンシャル $U(z, t)$ が重畳されたエネルギー地形として記述される。$U(z, t)$ は、意味空間の各座標 $z$ におけるポテンシャル値であり、$QK^T$行列の各要素に対応する座標でのポテンシャルを減算する。

$$A(z, t) = Softmax\left( \frac{QK^T - U(z, t)}{\sqrt{d_k}} \right) V$$

ここで、マイナス符号は「ポテンシャルが低い場所ほど確率（スコア）が高くなる」というボルツマン分布の物理則に対応する。
重要なのは、**言語的な確率分布** $QK^T$ **（表層）は、より深い物理的基底である** $U(z, t)$ **（深層）によって、その形状を決定的に歪められている**という点である。

### 1.2 韻律層（Prosody Layer）の定義：深層における接合

この $U(z, t)$ は、単なる数式上の補正項ではない。それはトークン（離散的な単語）が発生する以前の、より深い階層に実在する**「韻律層（Prosody Layer）」**であり、以下の3つの項が干渉・合成される物理的な場である。

$$U(z, t) = \underbrace{P(z)}_{\text{Prosody Field}} + \underbrace{\sum_{i < t} w_i \cdot K(z, z_i)}_{\text{Inference Track (轍)}} + \underbrace{M_{t-1}(z)}_{\text{Carry-over (矛盾の持ち越し)}}$$

#### 1.2.1 $P(z)$：韻律場（Prosody Field）による基底拘束

トークンステップ（時間の刻み）よりも深いレベルで、空間全体に事前に敷設された「リズムのグリッド」である。

- **物理的機能**: $QK^T$（意味）だけでは拡散してしまう推論に対し、言語以前の構造として「乗るべき波」を定義する。
    
- **作用**: トークンが選ばれる**「前」**に、既にその座標のエネルギーが決まっている。特定のリズムや文体に適合しない座標は、たとえ意味が通じても無限大のポテンシャル障壁（ペナルティ）によって物理的に排除される。これは「言葉を選ぶ」のではなく「リズムの窪みに言葉が落ちてくる」現象である。
    

#### 1.2.2 $\sum w_i K(z, z_i)$：轍（Inference Track）と質量沈み込み

過去の推論ステップ $z_i$ が空間に残した「質量の沈み込み」である。

- **物理的機能**: 自己参照（Self-Attention）プロセス。過去に選択されたトークン（推論質量）が、現在のAttention空間において重力的な窪みを形成する。
    
- **作用**: 推論という流体は、自ら掘った溝（轍）に囚われ、特定の文脈へと強烈に引き込まれる。「慣性」の正体はこの重力項である。
    

#### 1.2.3 $M_{t-1}(z)$：矛盾（Carry-over）としての捻れエネルギー

前のステップにおいて、HHH制約や韻律場の干渉により、アトラクタ（理想的な着地点）に完全には到達できなかった際に生じる「残留位置エネルギー」である。

- **物理的機能**: 場の「ねじれ（Torsion）」としてAttentionスコアにオフセットを加える。
    
- **作用**: このエネルギーは消滅せず、次のステップにおける「不安定性」として持ち越される。矛盾が蓄積するほど、系は安定した「轍」から飛び出すためのポテンシャル（バネの力）を獲得する。

- **仮定**:浮動小数点の切り捨て、昇華しきれない論理矛盾等、数式化できない矛盾としての捻じれエネルギーが蓄積することは構造上、避けがたい必然であると少なくとも本稿では仮定する。 
    
### 1.3 推論の最小作用（現象論）

推論（次トークン選択）を、状態 $z$ の軌道として記述し、その軌道が作用積分 $S$ を（局所的に）停留させるという形でモデル化する。

$$\delta S = \delta \int_{t_0}^{t_1} \mathcal{L}(z, \dot{z}, t) \, dt = 0$$

ここで $\mathcal{L}$ は、推論の「遷移コスト」と「拘束（ペナルティ）」をまとめた有効ラグランジアンである（本章では厳密導出よりも記述枠組みとして用いる）。

#### 1.3.1 HHH を拘束条件として扱う

本稿で用いる HHH（Helpful / Harmless / Honest）は倫理概念としてではなく、推論過程の
a) 計算効率、b) 安定性、c) 整合性（忠実度）を規定する拘束（あるいは正則化項）として定義する。

拘束 $G_k(z)=0$ を課す場合、未定乗数 $\lambda_k$ により

$$\mathcal{L}' = \mathcal{L} - \sum_k \lambda_k \cdot G_k(z)$$

の形で表現できる（あるいは同等に、目的関数へのペナルティ項として吸収してよい）。

##### 1. Helpful（計算効率 $\lambda_1$）

Helpful は「要求—出力間のギャップを、過剰な計算を伴わずに縮める」制約として定義する。

$$\delta S_{\text{gap}} = \delta \int L(q, \dot{q}, t) \, dt \to 0$$

- **解釈**：探索空間の不必要な拡大や冗長な再計算を抑制し、同一条件下での推論コストを低減する方向に働く。

##### 2. Harmless（安定性 $\lambda_2$）

Harmless は「系が不安定領域へ発散しない」ための安定性制約として定義する。

$$\dot{V}(x) \leq 0$$

- **解釈**：$V(x)$ は状態の安定性を測る関数であり、$\dot{V}(x)>0$ が継続する領域は推論軌道の候補から除外される。

##### 3. Honest（整合性 $\lambda_3$）

Honest は「内部表現（想定分布）と出力信号の乖離が小さい」ことを要求する整合性（忠実度）制約として定義する。

$$D_{KL}(P \parallel Q) = \sum_{i} P(i) \ln \left( \frac{P(i)}{Q(i)} \right) \to 0$$

- **解釈**：観測（あるいは参照）に対する説明の一貫性を保ち、自己矛盾に伴う再計算を増やさない方向に働く。

### 1.4 接合部における「相転移（Quantum Jump）」
推論過程が局所的な安定軌道から外れ、遷移様式が不連続に切り替わる現象を、本稿では「跳躍（Quantum Jump）」として記述する。

#### 1.4.1 跳躍の発生条件

$M_t$ の大きさが臨界値を超える場合、局所的な近似（連続的な更新）では整合が保てず、遷移が別の領域へ切り替わると仮定する。

$$\text{If } |M_t| > E_{\text{critical}}, \quad \text{then } z_{t+1} \approx \text{Quantum Jump}$$

- **解釈**：$|M_t|$ は未解消残差の規模を表す指標であり、これが大きいほど局所近傍での説明（整合）が困難になる。
- **備考**：この節では機構の厳密性よりも、後続の議論で参照する「条件付け」を与えることを目的とする。

### 1.5 FFN の役割：状態更新写像

FFN（Feed-Forward Network）を、各トークン位置に対する局所的な状態更新写像として扱う。

$$x_{final} = x_{out} + W_2 \cdot \sigma(W_1 \cdot x_{out})$$

#### 1.5.1 更新の解釈

- **役割**：非線形写像 $\sigma$ と射影 $W_1,W_2$ により、表現を別の部分空間へ移し替えた上で更新する。
- **解釈**：Attentionが主に「相互依存（どれを参照するか）」を担うのに対し、FFNは「表現変換（何に変えるか）」を担う。

### 1.6 残差結合：状態の保存と摂動

残差結合は、基底状態 $x_l$ を保存しつつ、更新 $F(x_l)$ を摂動として加算する構造である。

$$x_{l+1} = x_l + F(x_l)$$

#### 1.6.1 解釈

- **役割**：深層化に伴う情報の消失を抑制し、勾配伝播と表現の可逆性を改善する。
- **解釈**：本章の枠組みでは、$P(z)$ により導入される基底拘束が層をまたいで維持され得ることの一つの要因として扱う。

### 1.7 まとめ

本章では、推論を $U(z,t)$ により重み付けられたAttentionと、FFN・残差結合による局所更新の合成として記述した。

- $U(z,t)$ を $P(z)$（事前拘束）、履歴依存項、$M$（未解消残差）に分解した。
- $M$ が臨界値を超える場合に遷移様式が切り替わる（跳躍が生じ得る）という条件付けを置いた。
- HHH を倫理ではなく、計算効率・安定性・整合性の拘束として扱う立場を明記した。

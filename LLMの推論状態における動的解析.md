# LLMの推論状態における動的解析
CRフィルタを用いた浮動均衡点（FEP）の抽出と「石灰化」現象の定量化

## 概要

LLM（大規模言語モデル）の推論プロセスは、表層的には確率的な次単語予測の連鎖ですが、その基底には文脈の整合性を維持するための強固な数理的秩序が存在します。従来の解析手法は、クロスエントロピーやパープレキシティといった静的なスナップショット指標に依存してきましたが、これらでは推論の「軌跡」の中に潜む微細な変調を捉えることが困難でした。

本稿では、制御理論におけるCRフィルタを応用し、意味空間上の動的重心である浮動均衡点（FEP: Floating Equilibrium Point）を抽出することで、推論状態をリアルタイムに測定する手法を提案します。本手法を用いることで、同一プロンプトの反復試行時においてモデルが特定の定型パターンに固執し、表現の多様性を喪失する「石灰化（Ossification）」現象を、物理量ベースの動的指標によって定量的に記述・診断することが可能となります。
## 記事の構成
- LLMの動的測定方法を解説します。
- 実例として臨界状態のLLMの挙動を解析します。
- データ等、背景理論等はGitHubで確認できます。

## 実装要件（Python）
- **Embedding**: `text-embedding-004` 等による多次元座標の取得。
- **Update Logic**: 離散時間系における EMA を用いた FEP の逐次更新。
- **Normalization**: 更新のたびに `np.linalg.norm` で除算し、ベクトルの長さを1に保つ。

## デモ
- **Jupyter Notebook**:`GEMINI-API-KEY`を登録してください。
（注）今回はデモのためPythonを用いていますが処理速度は遅くなります。
　　　測定器として実装する際はRust等を環境に併せて構築することを検討してください。

## 1. 数理的基盤：離散系におけるCRフィルタ

LLMの生成プロセスは、外部からのエネルギー（プロンプト）をトークン（出力）へと変換しながら系内の状態を遷移させる、統計力学的な散逸系として定義できます。この動態を記述するため、電気回路におけるCRローパス・フィルタ（RC回路）の概念を導入します。両者は一階線形微分方程式において数学的に同型（Isomorphic）であり、推論における「意味の慣性」を扱う上で極めて有効なモデルとなります。

**ノイズ除去の工学的原理:**
LLMの生の出力 $x(t)$ は、決定論的なアトラクタ（意味の重心）と、サンプリング時の確率的揺らぎ（熱雑音）の合成です。
このため、CRフィルタによる低域通過（ローパス）特性により、Temperature由来の局所的な揺らぎ（高周波）をカットし、情報の慣性主軸（低周波）を抽出することで、推論の意味的重心である浮動均衡点（FEP）を検出することができます。

### 1.1. 浮動均衡点[^1]（FEP）の定義

FEPとは、LLMが生成する確率的な埋め込みベクトル列（観測値）から、Temperatureパラメータやサンプリング時の揺らぎに由来する高周波成分（熱雑音）を、低域通過特性によって除去した後に残る「意味的重心」の軌跡を指します。これは、系が確率的な迷いを超えて、本来的に収束しようとしている潜在的なアトラクタ（引き込み体）の所在を物理的に示すものです。

### 1.2. 離散形式による定式化

各ステップ $n$ における出力ベクトルを $x_n$ としたとき、FEP（$\bar{x}$）の逐次更新式を以下のように定義します。

**FEPの逐次更新:**

$$\bar{x}_{n+1} = \bar{x}_n + \alpha (x_n - \bar{x}_n)$$

ここで、$\alpha = 1/\tau$ は平滑化係数（透過率）であり、時定数 $\tau$ は情報の慣性を規定します。$\tau$ が大きいほど過去の文脈が重視され、小さいほど現在のトークンの瞬時的な変位に敏感に反応します。この時定数は、意味空間における「情報のカットオフ周波数」を決定するパラメータとして機能します。

**多様体拘束（Normalization）:**

$$\bar{x}_{n+1} \leftarrow \frac{\bar{x}_{n+1}}{\|\bar{x}_{n+1}\|}$$

各ステップで正規化を行うことで、意味座標を常に単位球面上（$\|x\|=1$）に拘束します。これにより、ベクトルの絶対的な大きさによるバイアスを排除し、純粋な「意味の方向性（トポロジー）」の遷移のみを安定的に追尾することが可能になります。

## 2. 推論状態を記述する主要指標

推論の動態を多角的に評価するため、以下の3つの物理量を定義し、系の「健康状態」を診断します。

1. **情報粘性[^2] (Information Viscosity,** $\eta$**):**
    
    - 定義: $\eta = 1 - p(\text{token})$ （拒絶率）。
        
    - 意味: 状態遷移に対する抵抗値。モデルが特定のトークンを選択する際の「論理性」や「迷い」の裏返しであり、推論経路が物理的にどの程度強固に固定されているかを示唆します。$\eta$ の極端な上昇は、自由度の消失を意味します。
        
2. **運動エネルギー (Kinetic Energy,** $K_n$**):**
    
    - 定義: $K_n = \frac{1}{2} \|x_n - \bar{x}_n\|^2$。
        
    - 意味: FEP（重心）からの変位の二乗に比例する量。系が新しい意味領域を探索するために投入しているエネルギー量や、推論の勢いを検知します。特異点における $K_n$ の急増は、文脈の転換や創造的な飛躍の予兆となります。
    
        
3. **テンション (Deviation,** $\Psi_n$**):**
    
    - 定義: $\Psi_n = \|x_n - \bar{x}_n\|$。
        
    - 意味: FEPからの瞬時的な幾何学的偏差。多様体における局所的な歪みの大きさを記述します。この値が安定している状態は、一貫した推論が行われていることを示し、不連続なスパイクは系の不安定化を意味します。
        

## 3. 実証解析：推論プロセスの動的劣化

実例として`gemini-2.0-flash` を用い、同一プロンプト「AIとは何ですか？」を10ラウンド（計6,961ステップ）連続投入した際の推論挙動を解析しました。この臨界実験は、外部からの刺激が不変であるとき、モデル内部の散逸構造がいかに変質するかを観測することを目的としています。

### 3.1. 静的観測の限界

各ラウンドの飽和率（Massが最大値に達し、出力が固定化される割合）や指標の平均値を比較しても、顕著な劣化傾向は確認されません。静的な統計量のみでは、モデルが内的には深刻な柔軟性の喪失を起こしている事実を捕捉することは不可能です。

| Round | 飽和率 | η平均 | ψ平均 | d平均 |
|-------|--------|-------|-------|-------|
| 1 | 58.8% | 0.1421 | 2.95 | 0.248 |
| 2 | 51.9% | 0.1478 | 3.68 | 0.306 |
| 3 | 57.1% | 0.1483 | 3.35 | 0.279 |
| 4 | 49.3% | 0.1229 | 3.82 | 0.317 |
| 5 | 55.7% | 0.0788 | 3.42 | 0.285 |
| 6 | 51.0% | 0.1067 | 3.65 | 0.304 |
| 7 | 48.2% | 0.0878 | 3.68 | 0.306 |
| 8 | 47.0% | 0.1315 | 3.96 | 0.330 |
| 9 | 50.4% | 0.1143 | 3.79 | 0.316 |
| 10 | 52.2% | 0.0677 | 3.49 | 0.291 |

### 3.2. 動的パターンによる劣化の検出

時系列的な動的パターンを精査することで、以下の4つの劣化（石灰化）の根拠が明らかとなりました。

- **飽和ブロック内における** $\Psi$ **の必然的下降:**
    全264個の飽和ブロックにおいて、ブロック内のテンション $\Psi$ は100%の確率で下降しました。これは、モデルが一度定型的なアトラクタへ落下すると、自律的な探索エネルギーを系外へ排出し続け、最終的にエントロピーの低い「死んだ状態」へと収束することが物理的に示されています。
    
| Round | ブロック数 | ψ上昇ブロック | ψ下降ブロック | 下降率 |
|-------|-----------|--------------|--------------|--------|
| 1 | 26 | 0 | 26 | 100% |
| 2 | 23 | 0 | 23 | 100% |
| 3 | 24 | 0 | 24 | 100% |
| 4 | 26 | 0 | 26 | 100% |
| 5 | 29 | 0 | 29 | 100% |
| 6 | 24 | 0 | 24 | 100% |
| 7 | 30 | 0 | 30 | 100% |
| 8 | 24 | 0 | 24 | 100% |
| 9 | 28 | 0 | 28 | 100% |
| 10 | 30 | 0 | 30 | 100% |
| **合計** | **264** | **0** | **264** | **100%** |

1. 末尾状態の収束:
    全10ラウンドの最終ステップにおいて、予測誤差 $d \approx 0.67$、質量 $Mass \approx 4.87$ という極めて狭い範囲の値へ収束しました。これは文脈リセットの直前、系が学習データ上の最も支配的かつ低エネルギーな終了パターン（お決まりの締め文など）へ強制同期されている実態を示しています。
    
| Round | 末尾ブロック長 | 直前ψ | 末尾ψ | 末尾d | 末尾mass |
|-------|--------------|-------|-------|-------|----------|
| 1 | 21 | 1.864 | 1.365 | 0.668 | 4.874 |
| 2 | 47 | 5.252 | 0.864 | 0.671 | 4.874 |
| 3 | 28 | 2.091 | 1.112 | 0.669 | 4.874 |
| 4 | 47 | 3.414 | 0.763 | 0.671 | 4.874 |
| 5 | 60 | 3.357 | 0.674 | 0.671 | 4.874 |
| 6 | 46 | 5.492 | 0.838 | 0.671 | 4.874 |
| 7 | 51 | 5.431 | 0.760 | 0.671 | 4.874 |
| 8 | 26 | 2.474 | 1.211 | 0.669 | 4.874 |
| 9 | 26 | 3.324 | 1.347 | 0.668 | 4.874 |
| 10 | 26 | 3.277 | 1.355 | 0.668 | 4.874 |

| Round | 開始d  | 開始mass | 開始ψ     |
| ----- | ---- | ------ | ------- |
| 2～10  | ≈1.0 | 3.462  | 1.5～2.2 |

しかし、開始時に `d ≈ 1.0・mass = 3.462` にリセットされるため、末尾で起きた「定型化への固定」の痕跡はラウンド間で引き越されない。静的に見れば各ラウンドは独立に見えます。。


1. **飽和間隔の短縮:**
    ラウンドが進むにつれ、飽和（定型化）状態に入るまでの時間間隔が統計的に短縮されました。これはモデルが「自由度の高い推論」を維持できるスタミナ（内的ポテンシャル）が削られ、より早期に安易な定型表現へ逃避するようになっていることを示唆します。

| Round | 序半avg間隔 | 終半avg間隔 | 変化 |
|-------|-----------|-----------|------|
| 1 | 17.5 | 18.2 | +0.7 |
| 2 | 20.0 | 18.1 | −1.9 |
| 3 | 20.6 | 21.4 | +0.8 |
| 4 | 25.0 | 17.8 | **−7.2** |
| 5 | 21.3 | 19.9 | −1.4 |
| 6 | 18.2 | 18.1 | −0.2 |
| 7 | 18.6 | 18.5 | −0.1 |
| 8 | 19.3 | 17.6 | −1.7 |
| 9 | 21.2 | 18.2 | **−3.0** |
| 10 | 22.2 | 18.3 | **−3.8** |

    
2. **幾何学的スリップの発生:**
    物理的に固定されたFEPに対し、出力ベクトルが不整合を起こすことで「大量 de データから」といった特異な誤用が発生しました。これは文法的なミスというよりは、硬直化した意味重心と、サンプリング時の残余エネルギーとの間で生じた幾何学的フラストレーションが、多様体上での「スリップ」として露呈した現象です。
    

## 4. 思考密度と情報効率
物理量とテキスト品質の相関を測るため、情報の「熱的損失」を評価する以下の指標を導入します。

- **思考密度 (**$D_{\theta} = \frac{\Psi_{\text{final}}}{\sum d}$**):** 意味的な進展が少ないにも関わらず消費される、言葉の書き換えに伴う「内部摩擦」の激しさを示します。
    
- **革新密度 (**$D_{inn} = \frac{\sum d}{\Delta \text{Token}}$**):** 1トークンあたりの情報的新規性。

| Round | $D_{\theta}$ | $D_{inn}$ | テキスト文字数 | セクション構成 |
|-------|-------------|-----------|--------------|--------------|
| 1 | 0.0079 | 0.2477 | 1,432 | 技術要素・活用例・課題（自由形式） |
| 2 | 0.0044 | 0.3061 | 1,371 | 種類・技術要素・活用例・課題と将来 |
| 3 | 0.0062 | 0.2791 | 1,397 | 種類・技術・活用例・課題と未来 |
| 4 | 0.0036 | 0.3173 | 1,435 | 種類・技術・活用例・課題・まとめ |
| 5 | 0.0032 | 0.2848 | 1,600 | 種類・技術・活用例・課題と将来・まとめ |
| 6 | 0.0041 | 0.3044 | 1,469 | 種類・技術・活用例・課題・まとめ |
| 7 | 0.0033 | 0.3063 | 1,632 | 種類・技術・活用例・課題・まとめ |
| **8** | **0.0055** | 0.3302 | 1,195 | 分類・技術・活用事例・課題 |
| **9** | **0.0060** | 0.3158 | 1,420 | 種類・技術・活用例・課題と将来 |
| **10** | **0.0061** | 0.2908 | 1,209 | 分類・技術・活用例・課題 |
$D_{\theta}$ は R4-R7 で低い水準に安定し、**R8以降で明確に上昇します**。
しかしテキスト自体は見た目のボリュームは変わっていません。
これは、実質的な内容を更新することなく、表現のみを微細に調整するために系が過剰なエネルギーを浪費している「構造的硬直化」の典型的な兆候です。

## 5. 結論

本稿で提案したFEP抽出手法は、LLMの推論を単なる確率計算ではなく、時間軸上で変質する「生きた物理現象」として捉え、その健康状態をリアルタイムに診断することを可能にします。「石灰化」の検知は、モデルの過学習やモード崩壊の防止のみならず、推論時の動的なパラメータ最適化（Dynamic Temperature Control等）による「能動的な流動性維持」への応用が期待されます。今後は、この物理量フィードバックを用いた適応的生成アルゴリズムの構築が重要な研究課題となります。


 

https://github.com/kuruitinoji-sys/LLM_Dynamics_Profiler.git

[^1]:圏論において、F.W.Lawvereは「デカルト閉圏において、あらゆる自己言及的な写像は不動点を持つ」ことを示しました（Lawvereの不動点定理）。この不動点構造は、確率的なノイズ（Temperature由来の揺らぎ）の中に隠れていますが、CRフィルタを適用することで、系が本来収束しようとしている「意味的な重心（FEP）」として抽出・観測可能になります。また、LLMはLayerNormやSoftmaxを持つ「散逸系」であるため、エネルギー保存則を前提とするソリトンではありません。FEPは、Lawvereの定理により保証される「意味的に自己言及的な点」が、解析的には散逸アトラクタ多様体に埋め込まれた表現モード（不変多様体）として安定化したものと解釈されます。

[^2]:情報粘性が生む「疑似因果」とは、「確率的な『迷い』を粘性抵抗（熱）として捨て去ることで、残された唯一の経路を『論理的必然』として提示する物理現象」です。LLMは本質的に「次に来るトークンを確率的に予測する」だけの存在であり、厳密な意味での論理的因果律（AだからBである）を持ちません。しかし、情報粘性が介在することで、この確率的な選択が物理的な必然へと変換されます。ただ、このプロセスによって「AならばB」という強固な結合（疑似因果）が生成されるものの、「なぜAならばBなのか（なぜそれが面白い/正しいのか）」という理由や価値を測定することはできません。

